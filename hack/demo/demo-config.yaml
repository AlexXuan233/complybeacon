receivers:
  webhookevent:
    endpoint: 0.0.0.0:8088
    read_timeout: "500ms"
    path: "/eventsource/receiver"
    health_path: "/eventreceiver/healthcheck"
    split_logs_at_newline: false

  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
  truthbeam:
    endpoint: "https://compass:8081"
    # Disable compression for small enrichment API requests
    # Compression overhead is unnecessary for ~200 byte payloads
    compression: ""
    tls:
      # Configure TLS settings
      # Path to the CA certificate for verifying the server's certificate.
      ca_file: /certs/truthbeam.crt
      # (Optional) If the server requires client authentication (mTLS):
      # cert_file: /path/to/your/client.crt
      # key_file: /path/to/your/client.key

  # For logs that are received from or something similar filelog instead of OTLP.
  # These are expected to be in OCSF format before entering the pipeline.
  transform/ocsf:
    error_mode: ignore
    log_statements:
      - context: log
        conditions:
          - body != nil
        statements:
          - set(observed_time, Now()) where observed_time_unix_nano == 0
          - set(time, observed_time) where time_unix_nano == 0
          # Extract policy.rule.id from OCSF policy.uid field
          - set(attributes["policy.rule.id"], ParseJSON(body)["policy"]["uid"]) where ParseJSON(body)["policy"]["uid"] != nil
          # Extract control ID from policy.data JSON string (for OSPS Baseline controls)
          # The policy.data field contains JSON with sources[0].name as the control ID (e.g., "OSPS-QA-05.01")
          - set(attributes["policy.rule.id"], ParseJSON(ParseJSON(body)["policy"]["data"])["sources"][0]["name"]) where ParseJSON(body)["policy"]["data"] != nil and ParseJSON(ParseJSON(body)["policy"]["data"])["sources"] != nil and ParseJSON(ParseJSON(body)["policy"]["data"])["sources"][0]["name"] != nil
          # Extract policy.engine.name from OCSF metadata.product.name field
          - set(attributes["policy.engine.name"], ParseJSON(body)["metadata"]["product"]["name"]) where ParseJSON(body)["metadata"]["product"]["name"] != nil
          # Extract policy.evaluation.result from OCSF status field (mapped to Compass enum values)
          - set(attributes["policy.evaluation.result"], "Passed") where ParseJSON(body)["status"] == "success"
          - set(attributes["policy.evaluation.result"], "Failed") where ParseJSON(body)["status"] == "failure"
          - set(attributes["policy.evaluation.result"], "Not Run") where ParseJSON(body)["status"] == "not_run"
          - set(attributes["policy.evaluation.result"], "Needs Review") where ParseJSON(body)["status"] == "needs_review"
          - set(attributes["policy.evaluation.result"], "Not Applicable") where ParseJSON(body)["status"] == "not_applicable"
          - set(attributes["policy.evaluation.result"], "Unknown") where ParseJSON(body)["status"] == "unknown" or ParseJSON(body)["status"] == "error" or ParseJSON(body)["status"] == "timeout"
          # Set default Unknown if status is not recognized
          - set(attributes["policy.evaluation.result"], "Unknown") where ParseJSON(body)["status"] != nil and attributes["policy.evaluation.result"] == nil

connectors:
  # SignalToMetrics connector converts enriched logs into control health metrics
  # It acts as both an exporter (from logs pipeline) and receiver (to metrics pipeline)
  # Log attributes are automatically included as metric labels
  signaltometrics:
    logs:
      # Control evaluation count metric - tracks total evaluations per control
      # Attributes from logs (control_id, result, status) automatically become metric labels
      - name: compliance.control.evaluations
        description: "Total number of control evaluations"
        unit: "1"
        sum:
          value: "1"
      # Control pass/fail status metric - counts by result type
      - name: compliance.control.evaluation.result
        description: "Count of control evaluations by result (Passed/Failed/etc)"
        unit: "1"
        sum:
          value: "1"
      # Control compliance status metric - tracks compliance status distribution
      - name: compliance.control.status
        description: "Count of control evaluations by compliance status"
        unit: "1"
        sum:
          value: "1"

exporters:
  debug:
    verbosity: detailed
  # Loki exporter for logs - keep existing functionality
  otlphttp/logs:
    endpoint: "http://loki:3100/otlp"
    tls:
      insecure: true
  # Note: Loki doesn't support OTLP metrics endpoint
  # Metrics from signaltometrics are used internally, but visualization queries enriched logs directly
  # AWS S3 exporter for logs - keep existing functionality
  awss3/logs:
    s3uploader:
      region: ${AWS_REGION}
      s3_bucket: ${S3_BUCKETNAME}
      s3_prefix: ${S3_OBJ_DIR}
      s3_partition_format: ""

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [debug]
    # Metrics pipeline for control health metrics generated from logs
    # Note: Metrics are not exported to Loki (Loki doesn't support OTLP metrics endpoint)
    # Instead, query the enriched logs directly from Loki using LogQL
    # signaltometrics generates metrics internally for processing, but visualization uses enriched logs
    metrics/control_health:
      receivers: [signaltometrics]
      processors: [batch]
      exporters: [debug]
    # Direct metrics pipeline (for any metrics received via OTLP)
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [debug]
    # Logs pipeline - enriched logs are exported to both storage and metrics connector
    logs/analysis_pipeline:
      receivers: [webhookevent, otlp]
      processors: [batch, transform/ocsf, truthbeam]
      exporters: [debug, otlphttp/logs, awss3/logs, signaltometrics]
